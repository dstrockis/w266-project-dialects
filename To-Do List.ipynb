{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research To-Do List\n",
    "\n",
    "Data Exploration & Preparation:\n",
    "\n",
    "- Join Yelp datasets to get localized reviews (1) (complete)\n",
    "- Graph reviews on a map to display distribution (2) (complete)\n",
    "- Construct dialect labels, where dialect == state (3) (complete)\n",
    "- Construct dialect labels, where dialect == manually defined regions (4) (complete)\n",
    "- Clean and preprocess text data, using packages used in class (5) (complete)\n",
    "    - warning: you might remove some interesting phenomena by cleaning\n",
    "        - stop words might have removed a bunch of dialect richness\n",
    "        - punctuation might have removed a bunch of dialect richness\n",
    "    - use class packages for cleaning?\n",
    "    - use: https://github.com/yoonkim/CNN_sentence\n",
    "    - use: https://medium.com/@sabber/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b\n",
    "    - use: http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/\n",
    "- Remove proper nouns, like locations and names of businesses, landmarks, cities, etc (9) \n",
    "\n",
    "Dialect Identification:\n",
    "\n",
    "- Construct features (bag of words, tfidf, etc) for clustering (10)\n",
    "- Reduce dimensions if necessary (PCA) (13) \n",
    "- Somehow define distance metric that factors in location data (be careful not to over-do it, where location is the only thing that matters) (11)\n",
    "- Perform hierarchical clustering (12)\n",
    "- Graph clusters and compare to research (14)\n",
    "\n",
    "Dialect Classification:\n",
    "\n",
    "- Establish a baseline (complete)\n",
    "- Use classification models to perform dialect classification\n",
    "    - Try a basic model w/improvements, dialect == state == label (15)\n",
    "    - Try a basic model w/improvements, dialect == region == label (16)\n",
    "        - Why is the baseline model so accurate? One class overpowers? (complete)\n",
    "        - Explore errors, strongest/weakest words\n",
    "        - Try getting rid of TF-IDF, might be a bad idea\n",
    "        - Try an n-gram model, try to get the model to pick up common little phrases\n",
    "        - Try and search the data set for similar phrases/synonyms across regions, and see if the model notices those differences\n",
    "    - Try a basic model w/improvements, dialect == cluster == label (17) \n",
    "    - Try a neural net w/embeddings, dialect == state == label (6)\n",
    "    - Try a neural net w/embeddings, dialect == region == label (7)\n",
    "        - install keras (complete)\n",
    "        - scp raw data to google vm, which has tf installed (complete)\n",
    "        - might need to up the size of the vm (complete)\n",
    "        - develop initial model following keras LSTM tutorial\n",
    "        - maybe try my hand at simple CNN using keras\n",
    "            - load sentences from data file\n",
    "            - clean text (code from class, or [this code](https://github.com/yoonkim/CNN_sentence))\n",
    "            - pad senteces to max length, this enables batching\n",
    "            - build a vocab index and map each word to an integer 0 -> size(vocab)\n",
    "            - use word2vec embeddings, or learn embedddings from scratch?\n",
    "            - ... (see tutorial and hw)\n",
    "- Inspect errors to check for patterns, check for giveaway words (8)\n",
    "\n",
    "Retry with other data sets:\n",
    "\n",
    "- Twitter data? (18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References:\n",
    "- http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/\n",
    "- https://medium.com/@sabber/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b\n",
    "- https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) two stage model might work better\n",
    "2) explore overfitting\n",
    "3) replace words with wordnethierarchy\n",
    "3) compare most strongly predicted w/weakly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
